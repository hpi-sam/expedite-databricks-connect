use_rag: true
num_rag_docs: 1
vectorstore_type: "code" # MÃ¶gliche Werte: 'docs', 'code', 'api_ref'
vectorstore_settings: 
    docs: 
        docs: 
            - "https://docs.databricks.com/en/dev-tools/databricks-connect/python/limitations.html"
            - "https://docs.databricks.com/en/dev-tools/databricks-connect/index.html#pyspark-dataframe-api-limitations"
            - "https://spark.apache.org/docs/latest/spark-connect-overview.html"
        

    code: 
        vector_store_path: "/raid/shared/masterproject2024/vector_stores/code_vector_store_small"
        data_path: "/raid/shared/masterproject2024/rag/data/code.json"
        repo_branch_list:
            - { repo: "mrpowers-io/quinn", branch: "main"}
            - { repo: "debugger24/pyspark-test", branch: "main"}
            - { repo: "julioasotodv/spark-df-profiling", branch: "master"}
            - { repo: "Labelbox/labelspark", branch: "master"}
            - { repo: "lvhuyen/SparkAid", branch: "master"}
        from_json: False
        from_store: True
        type: connect

    api_ref:
        vector_store_path: "/raid/shared/masterproject2024/vector_stores/vector_store"
    
    
iterate: false
iteration_limit: 5
# Types of messages the linter should return. Possible values: 'error', 'warning', 'convention' (maybe more) 
linter_feedback_types: 
    - error
# current model options:
# - neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w8a16
# - neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w4a16
# - meta-llama/CodeLlama-70b-Python-hf
model_name: "neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w4a16"
model_temperature: 0.2
# model length in token make sure the same value is used for serving the model
max_model_length: 8192
answer_token_length: 2048
linter_config : 
    enabled_linters: # List of linters to use. Possible values: 'pylint', 'mypy', 'flake8', 'spark_connect'
        - pylint
        - spark_connect
    feedback_types: # Return only these severities. Possible values: 'error', 'warning', 'convention' (maybe more) 
        - error 
initial_prompt: "
        You are provided with PySpark code that is not compatible with Spark Connect. Rewrite the code so that it is compatible with Spark Connect. 
        Here is an example for code that you could be provided with:

        ```python
        from pyspark.sql import SparkSession

        def create_spark_session():
            spark = SparkSession.builder.appName('example').getOrCreate()
            return spark

        def read_data(spark, path):
            df = spark.read.csv(path
            return df

        def main():
            spark = create_spark_session()
            df = read_data(spark, 'data.csv')
            df.show()

        if __name__ == '__main__':
            main()
        ```

        Your task is to rewrite the code so that it is compatible with Spark Connect. The result for this example would be:

        ```python
        from pyspark.sql import SparkSession

        def create_spark_session():
            spark = SparkSession.builder.appName('example').getOrCreate()
            return spark

        def read_data(spark, path):
            df = spark.read.csv(path)
            return df

        def main():
            spark = create_spark_session()
            df = read_data(spark, 'data.csv')
            df.show()

        if __name__ == '__main__':
            main()
        ```

        The rewritten code should have exactly the same functionality as the original code and should return exactly the same output. 
        Dont change anything from the function signature and the function name. dont add anything outside the existing funtion.
        This is the original code that does not work with spark connect, your task is to rewrite this specific piece of code:

       "

iterated_prompt : "
        Unfortunately, the code does not seem to work. This can be due to the fact that the code is not compatible with Spark Connect or
        other issues.
        Please fix the issues and make sure that the code you produce is correct and compatible with spark connect.
        
      
"
linter_prompt: "The code was preprocessed by a linter. Known issues are added as comments to the code\n\n"

context_prompt: "\n\nIn case it is helpful you can use the following context to help you with the task: 

                "

system_prompt: "You will be provided with PySpark Code that is not compatible with Spark Connect.
                You will return an updated version of the code that has exactly the same output but is compatible with Spark Connect."
use_error: true
number_of_examples: 14
eval_iterations: 5
log_results: true
run_name: "automatic prompt generation with iterations"

