# Vector Store Settings
num_rag_docs: 5
vectorstore_type: "api_ref" # MÃ¶gliche Werte: 'docs', 'code', 'api_ref'
vectorstore_settings: 
    docs: 
        docs: 
            - "https://docs.databricks.com/en/dev-tools/databricks-connect/python/limitations.html"
            - "https://docs.databricks.com/en/dev-tools/databricks-connect/index.html#pyspark-dataframe-api-limitations"
            - "https://spark.apache.org/docs/latest/spark-connect-overview.html"
        

    code: 
        vector_store_path: "/raid/shared/masterproject2024/vector_stores/code/"
        data_path: "/raid/shared/masterproject2024/rag/data/code.json"
        repo_branch_list:
            - { repo: "mrpowers-io/quinn", branch: "main"}
            - { repo: "debugger24/pyspark-test", branch: "main"}
            - { repo: "julioasotodv/spark-df-profiling", branch: "master"}
            - { repo: "Labelbox/labelspark", branch: "master"}
            - { repo: "lvhuyen/SparkAid", branch: "master"}
        from_json: False
        from_store: True
        type: connect

    api_ref:
        vector_store_path: "/raid/shared/masterproject2024/vector_stores/api/complete"
        split_documents: False
        chunk_size: 512
        chunk_overlap: 50
    

# Iteration Settings    
iterate: false
iteration_limit: 3


# Linter Settings
linter_config : 
    enabled_linters: # List of linters to use. Possible values: 'pylint', 'mypy', 'flake8', 'spark_connect'
        - pylint
        - spark_connect
    feedback_types: # Return only these severities. Possible values: 'error', 'warning', 'convention' (maybe more) 
        - error 


# Models Settings
model_name: "neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w4a16"
# current model options:
#  - neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w8a16
#  - neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w4a16 
#  - meta-llama/CodeLlama-70b-Python-hf
#  - Qwen/Qwen2.5-Coder-32B-Instruct-AWQ
model_temperature: 0.2
embedding_model_name: "nvidia/NV-Embed-v2"
max_model_length: 16.384 # model length in token make sure the same value is used for serving the model
answer_token_length: 2048


# Prompt Settings
generate_prompt: false # If true, the prompt will be generated by the LLM. If false initial_prompt and iterated_prompt will be used.
use_error: true
use_rag: false
initial_prompt: "
        Update the provided PySpark code to be compatible with Spark Connect.
        The rewritten code should have exactly the same functionality as the original code and should return exactly the same output.
        This is the original code that does not work with spark connect:
        
        "

iterated_prompt : "
        Unfortunately, the code does not seem to work. This can be due to the fact that the code is not compatible with Spark Connect or
        other issues.
        Please fix the issues and make sure that the code you produce is correct and compatible with spark connect.
        
      
"
linter_prompt: "\n\nIssues in the code detected by the linter are listed here:

        "

context_prompt: "\n\nIn case it is helpful you can use the following context to help you with the task: 

                "

system_prompt: "You are a helpful assistant that helps to migrate Spark code to Spark Connect. You are tasked with updating the provided PySpark code to be compatible with Spark Connect. The rewritten code should have exactly the same functionality as the original code and should return exactly the same output.
"

first_step_prompt: "I want to update the provided PySpark code to be compatible with Spark Connect.
        The rewritten code should have exactly the same functionality as the original code and should return exactly the same output.
        Could you first give me an explanation of what you would change about the code and list Spark functions you would use instead?
        Do not generate the updated code yet.

        This is the original code that does not work with Spark Connect:
"

# Experiment Settings
number_of_examples: 18
eval_iterations: 10
log_results: true
run_name: nan
