use_rag: true
num_rag_docs: 1
vectorstore_type: "code" # MÃ¶gliche Werte: 'docs', 'code', 'api_ref'
vectorstore_settings: 
    docs: 
        docs: 
            - "https://docs.databricks.com/en/dev-tools/databricks-connect/python/limitations.html"
            - "https://docs.databricks.com/en/dev-tools/databricks-connect/index.html#pyspark-dataframe-api-limitations"
            - "https://spark.apache.org/docs/latest/spark-connect-overview.html"
        

    code: 
        vector_store_path: "/raid/shared/masterproject2024/vector_stores/code_vector_store_small"
        data_path: "/raid/shared/masterproject2024/rag/data/code.json"
        repo_branch_list:
            - { repo: "mrpowers-io/quinn", branch: "main"}
            - { repo: "debugger24/pyspark-test", branch: "main"}
            - { repo: "julioasotodv/spark-df-profiling", branch: "master"}
            - { repo: "Labelbox/labelspark", branch: "master"}
            - { repo: "lvhuyen/SparkAid", branch: "master"}
        from_json: False
        from_store: True
        type: connect

    api_ref:
        vector_store_path: "/raid/shared/masterproject2024/vector_stores/vector_store"
    
    
iterate: false
iteration_limit: 5
# Types of messages the linter should return. Possible values: 'error', 'warning', 'convention' (maybe more) 
linter_feedback_types: 
    - error
# current model options:
# - neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w8a16
# - neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w4a16
# - meta-llama/CodeLlama-70b-Python-hf
model_name: "neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w4a16"
model_temperature: 0.2
# model length in token make sure the same value is used for serving the model
max_model_length: 8192
answer_token_length: 2048
linter_config : 
    enabled_linters: # List of linters to use. Possible values: 'pylint', 'mypy', 'flake8', 'spark_connect'
        - pylint
        - spark_connect
    feedback_types: 
        - error
        - warning  # Return only these severities. Possible values: 'error', 'warning', 'convention' (maybe more)
initial_prompt: "
        You are provided with PySpark code that is not compatible with Spark Connect. Rewrite the code so that it is compatible with Spark Connect.
        The rewritten code should have exactly the same functionality as the original code and should return exactly the same output.
        This is the original code that does not work with spark connect.
        
        "
iterated_linter_prompt : "
        Unfortunately, the code does not seem to work. This can be due to the fact that the code is not compatible with Spark Connect or
        other issues.
        Please fix the issues and make sure that the code you produce is correct and compatible with spark connect.
        
      
"
linter_prompt: "The code was preprocessed by a linter. Known issues are added as comments to the code\n\n"

context_prompt: "\n\nIn case it is helpful you can use the following context to help you with the task: 

                "

system_prompt: "You will be provided with PySpark Code that is not compatible with Spark Connect.
                You will return an updated version of the code that has exactly the same output but is compatible with Spark Connect.
                Only return code blocks."
use_error: true
number_of_examples: 14
eval_iterations: 5
log_results: false
run_name: null

